\section{Conclusion}

In this work we explored the problem of Infinite Armed Bandits. We gave the notion of Unseen regret for evaluating agents in this setting. Then we proposed a method called Surplus weighted curiosity using which agents can achieve lower regret. We also empirically evaluated eight agents in three environments.

In the future one may look at Fair algorithms that use the notion of Surplus weighted curiosity. It is also interesting to explore the theoretical regret bounds of such methods. One may also look at non-bandit settings where a notion of surplus can be defined and used.